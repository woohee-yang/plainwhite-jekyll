---
title: "[파이토치 첫 걸음] 1. 파이토치 기본" ## 포스트 제목
category:       
    - Pytorch
tags:           
    - basic
comments:  true
use_math : true
last_modified_at : 2020-06-23
toc: true
---

`파이토치 첫 걸음` 정리입니다.

- 책 제목 : 파이토치 첫 걸음
- 출판사 : JPub, 제이펍
- 저자 : 두세교
- 역자 : 김완섭

---

# 1. 파이토치 패키지 구성


**1\.** torch
- 메인 네임스페이스로 텐서 등 다양한 수학 함수가 이 패키지에 포함
- Numpy와 같은 구조를 가짐

**2\.** torch.autograd
- 자동 미분을 위한 함수가 포함
- 자동 미분의 on/off를 제어하는 콘텍스트 매니저(enable_grad / no_grad)나 자체 미분 가능 함수를 정의할 때 사용하는 기반 클래스인 **Funtion** 등이 포함

**3\.** torch.nn
- 신경망을 구축하기 위한 다양한 데이터 구조나 레이어 등이 정의
- 예를 들어, Convolution, LSTM, ReLU등의 활성 함수나 MSELoss 등의 손실 함수도 포함

**4\.** torch.optim
- 확률적 경사 하강법(SGD)를 중심으로 한 파라미터 최적화 알고리즘 구현
- 추후 파이토치 내 최적화기 정리 요망

**5\.** torch.utils.data
- SGD의 반복 연산을 실행할때 사용하는 미니 배치용 유틸 함수 포함

**6\.** torch.onnx
- ONNX(Open Neural Network Exchange) 포맷으로 모델을 내보낼때(export) 사용
- ONNX는 서로 다른 딥러닝 프레임워크 간 모델을 공유할 때 사용하는 포맷 (책에서는 pytorch -> caffe 예제 있음)

---

# 2. 텐서(Tensor)


- 파이토치에서 다차원 배열을 처리하기 위한 가장 기본 데이터 구조
- Numpy의 ndarray와 거의 같은 API를 가짐
- GPU 연산 지원함.
- 각 데이터형별로 정의되어 있다. 
- ex. 32비트 유동소수점 : torch.FloatTensor / 64비트 부호있는 정수 : torch.LongTensor
- GPU 연산은 cuda 모듈 호출로 사용 가능 (ex. torch.cuda.FloatTensor)

---

## 2.1 텐서 생성과 변환


- torch.tensor 함수로 다차원 list, ndarray 형 자료를 넣어 텐서로 변환 가능
- Numpy처럼 `arange`, `linspace`, `logspace`, `zeros`, `ones`, `zeros_like`, `ones_like` 와 같이 다양한 텐서 생성 함수도 지원
- device 인자로 텐서 사용 장비 지정 가능 or to(device) 함수로 지정
- torch.tensor 함수 :
    + Parameters : data / dtype / device / requires_grad / pin_memory(Works only for CPU, default:False)
    + Return : torch.Tensor class type
    + `default dtype = None`
    + 항상 data를 복사한다.
    + 복사 회피 법 Tensor형 data -> torch.Tensor.requires_grad() or torch.Tensor.detach() 함수 사용
    + 복사 회피 법 Numpy data -> torch.as_tensor() 함수 사용
    + 모든 데이터를 읽어 구조화 하므로 torch.tensor(x) == x.clone().detach() 와 같은 효과를 냄
    + torch.tensor(x, requires_grad=True) == x.clone().detach().requires_grad(True)
- `tensor -> ndarray 시에 GPU상 텐서는 반드시 CPU로 이동 후 변환 가능`
- 텐서에 사용가능한 데이터 타입 :

![pf001](/assets/images/2020-06-23-pf001.PNG)

---

## 2.2 텐서 인덱스 조작


- ndarray와 같은 인덱스 조작 지원
- 슬라이스, 첨자 리스트, ByteTensor의 마스크 배열 지원
    + 마스크 배열 : 원 배열과 크기는 같으면서 각 요소가 True/False로 설정돼 있는 배열
    + ex. a = [1,2,3] -> a > 2 -> masked_a = [False, False, True]

---

## 2.3 텐서 연산


- 텐서는 사칙연산, 수학 함수, 선형 대수 계산 등이 가능하여 ndarray 대신 사용 가능
- 특히, 행렬곱이나 특이값 분해 등의 선형 대수 계산은 GPU를 사용할 수 있어 대규모 데이터 처리시 Numpy/Scipy보다 속도 빠름
- 사칙 연산 : 
    + `텐서 끼리 or 텐서 & 스칼라 값만 가능 / 텐서 & ndarray 불가능!`
    + `텐서 간 동일한 형일때만 가능`
    + `브로드캐스트(broadcast) 지원`
- 텐서 함수로 abs, sin, cos, exp, log, sqrt / mean, sum, max, min, std 등 기본 수학 및 집계 함수 지원
- 텐서 차원 변경 함수 : view, ...
- 텐서 결합 : cat, stack, ...
- 텐서 차원 교환 : t, transpose, permute, ...
- 텐서 선형 대수 연산자 : 
    + dot : 벡터 내적
    + mv : 행렬 & 벡터 곱
    + mm : 행렬 & 행렬 곱
    + matmul : 인수 종류에 따라 자동으로 dot, mv, mm 선택 실행
    + gesv : LU분해를 사용한 연립 방정식의 해
    + eig / symeig : 고유값 분해 / 대칭행렬보다 효율 좋은 알고리즘
    + svd : 특이치 분해

---

## 2.4 텐서와 자동 미분


- requires_grad 속성으로 자동 미분 기능 사용 활성 또는 비활성 설정 가능
- requires_grad가 적용된 텐서에 다양한 계산을 하게 되면 계산 그래프가 만들어지며, 여기에 backward 메서드를 호출하면 그래프로부터 자동으로 미분을 계산함
- `파이토치 0.3 이전 버전에서는 자동 미분을 사용하기 위해 Variable 클래스로 텐서를 래핑(wrapping)해야 했지만, 0.4부터는 텐서와 Variable이 통합됨`

---

## 참조

**1\.** pytorch 공식 문서 : <https://pytorch.org/docs/stable/tensors.html>