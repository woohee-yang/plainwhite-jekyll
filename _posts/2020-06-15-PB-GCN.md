---
title: "Part-Based Graph Convolutional Network for Action Recognition(PB-GCN)" ## 포스트 제목
category:       
    - Paper Review
tags:           
    - GCN
comments:  true
use_math : true
last_modified_at : 2020-06-15
toc: true
---

# 1. 논문 소개

- 제목 : Part-Based Graph Convolutional Network for Action Recognition
- 저자 : Kalpit Thakkar, P J Narayanan
- 학회 : The British Machine Vision Conference(BMVC)
- 발표일자 : 2018.09

- 구현 코드 깃허브 <https://github.com/kalpitthakkar/pb-gcn>

---

# 2. 문제

- 대용량 데이터를 이용한 행동 분류

---

# 3. 주요 공헌점

1) 일반적인 Part-Based Graph Convolutional Network 설계
    
    - 기존 ST-GCN 구조와 유사하지만, 사람 골격을 부위별로 나누어 학습
    
    - 부위를 합치기 위해 제안한 Aggregation function 사용

2) 3차원 관절 위치 데이터 대신 공간 및 시간 특징점을 사용하여 성능 향상

3) NTU-RGB+D60과 HDM05, 두 데이터셋 실험결과 좋은 성능을 보여줌

---

# 4. 제안 모델 및 방법

## 4.1 Part-Based Graph Network

1) Part-Based Graph

<그림>

- 사람 골격을 2, 4, 6개의 부위로 나누었다.
- 각 부위는 하위그래프로 표현되며, 아래 수식으로 전체 골격 $G$가 표현된다.

$$G = \bigcup_{p \in 1,...,n} P_{p}|P_{p} = (V_{p}, E_{p})$$

where,
$P_{p}$ : 부위 $p$ (하위그래프 $p$)
$V_{p}$ : 부위 $p$가 가진 노드 집합
$E_{p}$ : 부위 $p$가 가진 엣지 집합

# 5. 실험 데이터

# 6. 실험 결과

# 7. 정리